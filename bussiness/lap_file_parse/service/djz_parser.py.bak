from typing import Dict, Tuple, Any

from openpyxl.reader.excel import load_workbook
from openpyxl.styles import PatternFill
from openpyxl.comments import Comment
from openpyxl.styles import Font

from bussiness.lap_file_parse_v_two.config_of_djz import DJZConfig
from bussiness.lap_file_parse_v_two.service.djz_parse_style_one import djz_parse_style_one
from bussiness.lap_file_parse_v_two.service.djz_parse_style_three import djz_parse_style_three
from bussiness.lap_file_parse_v_two.service.djz_parse_style_two import djz_parse_style_two
from bussiness.lap_file_parse_v_two.model import LapFileTransfer
from bussiness.lap_file_parse_v_two.thread_pools import parse_pool
from common.excel_utils import excel_read_xlsx
from common.exception.file_exception import FileDownLoadError, FileParsedError
from common.string_utils import strings_join
from common.utils.string_utils import to_pretty_str

import os
from concurrent.futures import wait
from datetime import datetime
import pandas as pd
from pandas import DataFrame
import requests
from bussiness.dipp.dipp_file_utils import download_file
from common.utils.df_chain_utils import PandasChain
from logger import log
import chardet

"""
化学电解质里面，全都是 csv 文件，所以是按照 csv 进行解析的
"""


def split_location_info(row_idx: int, error_info: str, djz_config: DJZConfig) -> dict[tuple[int, int], str]:
    """
    获取 err 的相关信息
     [(2, 3), (4, 1), (5, 2)]
     {
        (2, 3)； error_info
        (4, 1)；error_info
        (5, 2); error_info
     }
    :param row_idx: 行号
    :param djz_config: header  信息
    :param error_info:  {row[column]}:{error_flag}:{column}, {row[column]}:{error_flag}:{column}, {row[column]}:{error_flag}:{column},
    :return:
    """

    row_location_info = {}
    cell_list = error_info.split(',')
    for cell in cell_list:

        if cell:
            items = cell.split(':')
            # f"{header}:{row[header]}:{error_flag}"
            warn_header = items[0]
            warn_value = items[1]
            warn_flag = items[2]
            col_idx = djz_config.header_of_template.index(warn_header) + 1
            error_info = strings_join(row_location_info.setdefault((row_idx, col_idx), ''),
                                      f"{warn_header} {warn_value} {warn_flag}")
            row_location_info[(row_idx, col_idx)] = error_info

    return row_location_info


# def highlight_error_rows(file_path, djz_config: DJZConfig, sheet_name=None):
#     # 加载Excel文件（只读模式关闭，允许写入）
#     wb = load_workbook(file_path)
#
#     # 如果指定了工作表名则使用，否则使用第一个工作表
#     if sheet_name:
#         ws = wb[sheet_name]
#     else:
#         ws = wb.active  # 默认使用活动工作表
#
#     # 定义黄色填充样式（RGB颜色：FFFF00）
#     yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
#
#     error_fill = PatternFill(start_color="ED7D31", end_color="ED7D31", fill_type="solid")
#
#     error_col_idx = len(djz_config.header_of_template)
#     if error_col_idx is None:
#         log.info("请检查表头是否正确")
#         return
#     #
#     # # 遍历数据行（从第 4 行开始，跳过表头）
#     for row in ws.iter_rows(min_row=4):
#         # 获取当前行的行号（如第5行、第6行...）
#         current_row_num = row[0].row
#
#         # 获取当前行的ERROR列单元格
#         # 直接获取第4列（ERROR列）的单元格
#         error_cell = ws.cell(row=current_row_num, column=error_col_idx)
#         error_value_info = error_cell.value
#         # 如果ERROR列非空，对A-D列（1-4列）染色
#         if error_value_info not in (None, ""):
#             log.info(f"遇到异常的列 {error_cell.value}")
#
#             # col_idx 列号， 1 对应 A 列，  2 对应 B 列
#             # 整行染色，
#             for col_idx in range(1, error_col_idx):  # A(1)到D(4)
#                 cell = ws.cell(row=current_row_num, column=col_idx)
#                 cell.fill = yellow_fill
#
#             # 异常的单元格再进行删除
#             #  f" {row[column]}:{error_flag}:{column}, {row[column]}:{error_flag}:{column}, {row[column]}:{error_flag}:{column},
#             # def split_location_info(row_idx: int, error_info: str, djz_config: DJZConfig) -> dict[tuple[int, int], str]:
#             error_cell_map = split_location_info(row_idx=current_row_num, error_info=error_value_info,
#                                                  djz_config=djz_config)
#
#             print(f" 获取到的异常数据行列信息为 {error_cell_map}")
#
#             for (row_idx, col_idx), info in error_cell_map.items():
#                 # dv = DataValidation(
#                 #     type="textLength",  # 不限制输入内容
#                 #     showInputMessage=True,  # 选中时显示提示
#                 #     prompt=info,
#                 #     showErrorMessage=False  # 关闭错误提示（不校验）
#                 # )
#                 target_cell = ws.cell(row=row_idx, column=col_idx)
#                 target_cell.fill = error_fill
#                 # ws.add_data_validation(dv)
#                 # dv.add(target_cell)  # 将规则应用到该单元格
#                 comment = Comment(text=f"{info}", author="")
#                 target_cell.comment = comment
#
#     # # 删除第3列（性别列，索引为3）
#     # ws.delete_cols(idx=error_col_idx)
#
#     wb.save(file_path)
#     log.info(f"渲染文件结束：{file_path}")


def highlight_error_rows(file_path, djz_config: DJZConfig, sheet_name=None):
    # 加载Excel文件（只读模式关闭，允许写入）
    wb = load_workbook(file_path)

    # 如果指定了工作表名则使用，否则使用第一个工作表
    if sheet_name:
        ws = wb[sheet_name]
    else:
        ws = wb.active  # 默认使用活动工作表

    # 定义黄色填充样式（RGB颜色：FFFF00）
    yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

    error_fill = PatternFill(start_color="ED7D31", end_color="ED7D31", fill_type="solid")

    error_col_idx = len(djz_config.header_of_template)
    if error_col_idx is None:
        log.info("请检查表头是否正确")
        return
    #
    # # 遍历数据行（从第 4 行开始，跳过表头）
    for row in ws.iter_rows(min_row=4):
        # 获取当前行的行号（如第5行、第6行...）
        current_row_num = row[0].row

        # 获取当前行的ERROR列单元格
        # 直接获取第4列（ERROR列）的单元格
        error_cell = ws.cell(row=current_row_num, column=error_col_idx)
        error_value_info = error_cell.value
        # 如果ERROR列非空，对A-D列（1-4列）染色
        if error_value_info not in (None, ""):

            # col_idx 列号， 1 对应 A 列，  2 对应 B 列
            # 整行染色，
            for col_idx in range(1, error_col_idx + 1):  # A(1)到D(4)
                cell = ws.cell(row=current_row_num, column=col_idx)
                cell.fill = yellow_fill

    wb.save(file_path)
    log.info(f"渲染文件结束：{file_path}")


def upload_template_file(template_file_path: str, df_chain: PandasChain, request: LapFileTransfer,
                         djz_config: DJZConfig):
    log.info(f"开始进行上传文件准备")
    with pd.ExcelWriter(template_file_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:
        # 获取工作簿对象并设置默认显示的Sheet
        wb = writer.book
        target_sheet = wb[DJZConfig.template_sheet_name]  # 要默认显示的Sheet名称
        wb.active = wb.index(target_sheet)
        # 设置冻结窗格：冻结 C4 单元格上方的行（前三行）和左侧的列（A、B 列）
        # wb.freeze_panes = "C4"  # 也可使用坐标 (row=4, column=3)

        startrow = writer.book[DJZConfig.template_sheet_name].max_row
        # 将新数据追加到指定sheet，不包含表头
        df_chain.df.to_excel(writer, sheet_name=DJZConfig.template_sheet_name, startrow=startrow, header=False,
                             index=False)

    # ===========================================================
    # 进行 excel 的行染色
    highlight_error_rows(template_file_path, sheet_name=DJZConfig.template_sheet_name, djz_config=djz_config)
    # ===========================================================

    log.info(f"开始上传dipp {template_file_path}")
    # 文件处理
    # 上传文件

    request.upload_template_file_to_dipp(template_save_path=template_file_path)

    log.info(f"结果文件上传完成:{template_file_path}")


def upload_template_data_to_dipp(df_chain: PandasChain, token: str):
    log.info(f"开始进行上传数据准备")
    # df_chain.print()

    send_data_to_dipp = (df_chain.header_rename_if_exist(DJZConfig.header_map_template_to_dipp)
                         .read_as_str()
                         .return_dict())

    post_config = DJZConfig.batch_add_to_dipp(token=token, data=send_data_to_dipp)

    # print(f"============================")
    # print(post_config.get('url'))
    # print(post_config.get('payload'))
    # print(post_config.get('headers'))
    # print(post_config.get('timeout'))
    # print(f"============================")
    # data = {'entry': [{'date': '2025/08/01', 'samplename': '1904019'}]}
    # ============== 测试染色，暂时关闭
    try:
        response = requests.post(
            url=post_config.get('url'),
            json=post_config.get('payload'),  # 自动序列化为JSON并设置Content-Type
            # json=data,  # 自动序列化为JSON并设置Content-Type
            headers=post_config.get('headers'),
            timeout=post_config.get('timeout'),  # 超时时间（秒）
        )

        log.info(
            f"\n=== 向 dipp 上传数据，请求响应 ===\n"
            f"URL: {response.request.url}\n"
            f"状态码: {response.status_code}\n"
            f"耗时: {response.elapsed.total_seconds():.2f}s\n"
            f"响应头: {dict(response.headers)}\n"
            f"响应体: {response.text[:500] + ('...' if len(response.text) > 500 else '')}"
        )
    except ValueError:
        log.error("响应不是有效的JSON格式")


def multi_thread_parse(file_save_path: str, djz_config: DJZConfig) -> dict[str, DataFrame]:
    # try:
    #
    #
    # except KeyError as e:
    #     log.error(f"错误: 列名不存在，请检查模板映射或数据格式： {e}")
    #     raise FileParsedError(file_path=file_save_path, message=f"错误: 列名不存在，请检查模板映射或数据格式： {e}")
    # except Exception as e:
    #     log.error(f"文件 {file_save_path} 下载&解析遇到异常 {e}")
    #     raise FileParsedError(file_path=file_save_path, message=f"文件 {file_save_path} 下载&解析遇到异常 {e}")
    # 文件下载，下载到本地
    log.debug(f"开始解析文件 {file_save_path}")

    with open(file_save_path, 'rb') as f:
        # 读取样本数据（避免读取整个大文件）
        raw_data = f.read(1024)
    result = chardet.detect(raw_data)
    bianma = result['encoding']

    # 根据第一行判断到底是哪个文件
    with open(file_save_path, 'r', encoding=bianma) as f:
        first_line = f.readline()  # 读取第一行，返回字符串（包含换行符\n）

    if first_line.startswith("日期,轮次号,ID,SID,批号,"):
        log.debug("样式文件 1 的解析")
        pf_chain = djz_parse_style_one(file_save_path, bianma, djz_config=djz_config)
        pf_type = "master"
    elif first_line.startswith("样本序号,样本条码,样本类型,检测项目"):
        log.debug("样式文件 2 的解析")

        pf_chain = djz_parse_style_two(file_save_path, bianma, djz_config=djz_config)
        pf_type = "master"
    elif first_line.startswith("ID, Date , Time , Serial , PID ,"):
        log.debug("样式文件 3 的解析")
        pf_chain = djz_parse_style_three(file_save_path, bianma, djz_config=djz_config)
        pf_type = "slave"
    elif first_line.startswith("This file is tab-delimited"):
        log.debug("糖化血红蛋白")
        pf_chain = djz_parse_style_three(file_save_path, bianma, djz_config=djz_config)
        pf_type = "slave"
    else:
        #  def __init__(self, file_path: str, message: str = "文件下载异常"):
        raise FileDownLoadError(file_path=file_save_path,
                                message=f"下载到的文件第一行，无法识别是哪种类型的文件，{first_line}")

    # return {
    #     'type' : pf_type,
    #     'data': pf_chain,
    # }
    log.info(f"文件解析结束")
    return pf_chain


def djz_parse_csv_file(request: LapFileTransfer, djz_config: DJZConfig):
    record = request.record
    save_dir = djz_config.get_save_dir(f"{request.time_uuid}-{record}")
    # ===============================================================================
    # template 文件下载，然后解析获取 headers,
    # 最后的数据还要写入到这个文件中，然后传递回 dipp
    # # ===============================================================================
    # log.info("下载 模板文件，然后解析出 header")
    template_file_url = request.parse_template_file_url()
    template_save_path = os.path.join(save_dir, f"化学电解质_{request.record}_{request.time_uuid}.xlsx")

    #
    # # ===============================================================================
    # # 文件下载下来保存的 path
    # # ===============================================================================
    # # $V(类别1.csv,类别2.csv,类别3.csv)$
    complete_file_download_urls = request.parse_data_file_url()
    download_file_save_path = request.fetch_data_file_save_path(save_dir)
    # # 需要下载 模板文件
    complete_file_download_urls.append(template_file_url)
    download_file_save_path.append(template_save_path)
    # # 保存文件
    #
    # # ===============================================================================
    # # 多线程处理，进行文件下载解析
    # # ===============================================================================
    # log.info(f"开始下载文件 {to_pretty_str()}")
    print(f"开始加载处理文件 {download_file_save_path}")
    futures = [
        parse_pool.submit(
            download_file,
            download_url,
            request.token,
            download_file_save_path[i]
        )
        for i, download_url in enumerate(complete_file_download_urls)
    ]

    # 阻塞直到所有任务完成（可设置超时）
    wait(futures, return_when="ALL_COMPLETED")
    # for future in futures:
    #     if future.exception() is not None:
    #         print(f"任务执行异常: {future.exception()}")
    #     else:
    #         print(f"任务结果: {future.result()}")

    # done, not_done = wait(futures, return_when="ALL_COMPLETED")
    # results = [future.result() for future in done]  # 按完成顺序获取结果
    #
    log.info(f"解析模板: {template_save_path} ")
    pf = excel_read_xlsx(file=template_save_path, sheet_name=djz_config.template_sheet_name)
    djz_config.header_of_template = PandasChain(pf).return_row_data_type_use_list(row_index=1)
    # 这个是标识这一行是有异常值
    djz_config.header_of_template.append("ERROR")

    log.info(f"解析到模板 header {to_pretty_str(djz_config.header_of_template)}")

    log.info(f"开始解析 data 文件")
    download_file_save_path.remove(template_save_path)
    # for file_path in download_file_save_path:
    #     pass
    futures = [
        parse_pool.submit(
            multi_thread_parse,
            save_path,
            djz_config
        )
        for i, save_path in enumerate(download_file_save_path)
    ]
    #
    # # 获取所有结果（按完成顺序）
    log.info("解析完成，进行数据合并")
    results = [future.result() for future in futures]
    #
    # # # 按原文件顺序整理结果
    base_pf_chain = PandasChain.of_empty_with_headers(djz_config.header_of_template).read_as_str()
    # #
    # print(base_pf_chain.df.shape)  # 查看行数是否真的为0
    # print(base_pf_chain.df.head())  # 检查是否有隐藏的NaN或空字符串
    #
    for pf_chin in results:
        # print("=================")
        # print(pf_chin.df.shape)  # 查看行数是否真的为0
        # print(pf_chin.df.head())  # 检查是否有隐藏的NaN或空字符串
        base_pf_chain.df_of_same_header_update(source_df=pf_chin.df,
                                               primary_header=djz_config.file_join_columns)

    # 调整写入 excel 的顺序
    base_pf_chain.column_select_need(djz_config.header_of_template)

    log.info("数据合并完成，进行文件写入、上传 dipp ")

    # def upload_template_file(template_file_path: str, df_chain: PandasChain, request: LapFileTransfer,
    #                          djz_config: DJZConfig):
    future1 = parse_pool.submit(upload_template_file, template_save_path, base_pf_chain, request, djz_config)
    #
    # # def upload_template_data_to_dipp(df_chain: PandasChain, token: str):
    future2 = parse_pool.submit(upload_template_data_to_dipp, base_pf_chain, request.token)

    # 等待两个任务都完成（不获取结果）
    # wait([future1, future2], return_when="ALL_COMPLETED")  # 阻塞直到所有任务结束
    done, not_done = wait([future1, future2], return_when="ALL_COMPLETED")
    for future in done:
        try:
            future.result()  # 这会重新抛出任务中的任何异常
        except Exception as e:
            print(f"任务 {getattr(future, 'task_name', '未知任务')} 出错: {e}")
            # 处理异常
